{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fileio\n",
    "import pydata\n",
    "import shapes\n",
    "#import numpy as np\n",
    "#import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'shapes' from '/home/nelson/Data/kba/shapes.py'>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(fileio)\n",
    "reload(shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fileio.InputData('arecaceae.csv')\n",
    "data.iucnFile('arecaceae_categories.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupFiles('arecaceae_groups_assignments.csv', 'arecaceae_group_diversity.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Arecaceae': 3000}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.taxonGroupsInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouplist = []\n",
    "for igr, gr in ennumerate(sorted(data.taxonGroupsInfo.keys())):\n",
    "    #\n",
    "    # Find out minimum spp number to apply criterion B2 for each group\n",
    "    #\n",
    "    groupDict = {ix:[data.taxonGroupsInfo[x], 2] for ix,x in enumerate(grouplist)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "spp2groupDict = {}\n",
    "for ispp, spp in enumerate(sorted(data.taxonGroups.keys())):\n",
    "    tgr = data.taxonGroups[spp]['group']\n",
    "    spp2groupDict[ispp] = grouplist.index(tgr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0,\n",
       " 1: 0,\n",
       " 2: 0,\n",
       " 3: 0,\n",
       " 4: 0,\n",
       " 5: 0,\n",
       " 6: 0,\n",
       " 7: 0,\n",
       " 8: 0,\n",
       " 9: 0,\n",
       " 10: 0,\n",
       " 11: 0,\n",
       " 12: 0,\n",
       " 13: 0,\n",
       " 14: 0,\n",
       " 15: 0,\n",
       " 16: 0,\n",
       " 17: 0,\n",
       " 18: 0,\n",
       " 19: 0,\n",
       " 20: 0,\n",
       " 21: 0,\n",
       " 22: 0,\n",
       " 23: 0,\n",
       " 24: 0,\n",
       " 25: 0,\n",
       " 26: 0,\n",
       " 27: 0,\n",
       " 28: 0,\n",
       " 29: 0,\n",
       " 30: 0,\n",
       " 31: 0,\n",
       " 32: 0,\n",
       " 33: 0,\n",
       " 34: 0,\n",
       " 35: 0,\n",
       " 36: 0,\n",
       " 37: 0,\n",
       " 38: 0,\n",
       " 39: 0,\n",
       " 40: 0,\n",
       " 41: 0,\n",
       " 42: 0,\n",
       " 43: 0,\n",
       " 44: 0,\n",
       " 45: 0,\n",
       " 46: 0,\n",
       " 47: 0,\n",
       " 48: 0,\n",
       " 49: 0,\n",
       " 50: 0}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spp2groupDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_threshod = 10000 # If user knows ranges of all species within group, he should select the 25th percentile\n",
    "for sp in data.points:\n",
    "    point_list = [x for x in data.points[sp].keys()]\n",
    "    tarea = shapes.area_estimator(point_list)\n",
    "    if not data.taxonGroups[sp]['range_size']:\n",
    "        data.taxonGroups[sp]['range_size'] = tarea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myar = shapes.KBA('/home/nelson/Dropbox/Humboldt/Postdoc/KBA_by_IUCN/Colombia_KBA', 'SitRecID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myar.spp_inclusion(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "myar.new_spp_table('test_kba_log.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tilas = data.getTiles(0.2, offsetLat=0.1, offsetLon=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ti in tilas:\n",
    "    print(data.tile2str(ti))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mysols = pydata.metasearchAlt(tilas, 0.2, 10000, 10, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mysols[0][0].aggrScore, mysols[0][0].score, mysols[0][0].ndmScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "' '.join(map(str, mysols[0][0].spp2crit[36]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(tilas[x].getName(), mysols[0][0].spp2crit[x]) for x in mysols[0][0].spp2crit.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm -r solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes.solution2shape(mysols, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "procAreas = {}\n",
    "\n",
    "filehandle = fiona.open('/home/nelson/Data/GIS/Areas_protegidas/RUNAP/runap2Polygon.shp', crs= 'EPSG:4326', encoding = 'utf8')\n",
    "for item in filehandle:\n",
    "    #self.polys.append(shape(item['geometry']))\n",
    "    procAreas[item['properties']['id_pnn']] = {\n",
    "        'shape': shape(item['geometry'])\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "procAreas['20170004']['shape'].contains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polys = []\n",
    "for ic in range(mysols[1][0].getSize()):\n",
    "    if mysols[1][0].getValue(ic) > 0:\n",
    "        y, x = irkeys[ic]\n",
    "        xBase = myfile.originN[0] + myfile.cellSize * x\n",
    "        yBase = myfile.originN[1] - myfile.cellSize * y\n",
    "        ocor = [(xBase + myfile.cellSize, yBase),\n",
    "            (xBase, yBase),\n",
    "            (xBase, yBase - myfile.cellSize),\n",
    "            (xBase + myfile.cellSize, yBase - myfile.cellSize)]\n",
    "        polys.append(Polygon(ocor))\n",
    "solpoly = unary_union(polys)\n",
    "\n",
    "for sp in myfile.points:\n",
    "    for lon, lat in myfile.points[sp]:\n",
    "        if solpoly.contains(Point(lon, lat)):\n",
    "            print (sp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solpoly.contains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = {\n",
    "    'geometry': 'Polygon',\n",
    "    'properties': {'id': 'int',\n",
    "                  'score': 'float',\n",
    "                  'NDMscore': 'float'},\n",
    "    }\n",
    "\n",
    "irkeys = list(myfile.index_reg.keys())\n",
    "\n",
    "for igr, gr in enumerate(mysols):\n",
    "    solpolcoll = []\n",
    "    multipol = None\n",
    "    filename = 'group_{0}.shp'.format(igr)\n",
    "\n",
    "    for its,  tsol in enumerate(gr):\n",
    "        polys = []\n",
    "        solpoly = None\n",
    "        for ic in range(tsol.getSize()):\n",
    "            if tsol.getValue(ic) > 0:\n",
    "                y, x = irkeys[ic]\n",
    "                xBase = myfile.originN[0] + myfile.cellSize * x\n",
    "                yBase = myfile.originN[1] - myfile.cellSize * y\n",
    "                ocor = [(xBase + myfile.cellSize, yBase),\n",
    "                    (xBase, yBase),\n",
    "                    (xBase, yBase - myfile.cellSize),\n",
    "                    (xBase + myfile.cellSize, yBase - myfile.cellSize)]\n",
    "                polys.append(Polygon(ocor))\n",
    "        solpoly = unary_union(polys)\n",
    "        \n",
    "        if its == 0:\n",
    "                with fiona.open(filename, 'w', 'ESRI Shapefile', schema, from_epsg(4326)) as c:\n",
    "                    c.write({'geometry': mapping(solpoly),\n",
    "                        'properties': {'id': ip,\n",
    "                                      'score':  tsol.aggrScore,\n",
    "                                      'NDMscore': tsol.ndmScore}\n",
    "                            })\n",
    "\n",
    "        else:\n",
    "            with fiona.open(filename, 'a', 'ESRI Shapefile', schema, from_epsg(4326)) as c:\n",
    "                c.write({'geometry': mapping(solpoly),\n",
    "                    'properties': {'id': ip,\n",
    "                                      'score':  tsol.aggrScore,\n",
    "                                      'NDMscore': tsol.ndmScore}\n",
    "                        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for spp in [tilas[x].getName() for x in mysols[0][0].spp2crit.keys()]:\n",
    "    print(spp, len(data.points[spp]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.tile2str( mysols[1][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mysols = pydata.metasearchAlt(tilas, 0.2, 1000, 500, 2)\n",
    "\n",
    "for ig, group in enumerate(mysols):\n",
    "    print ('#' * 50)\n",
    "    print ('Group {0}'.format(ig))\n",
    "    for iso, so in enumerate(group):\n",
    "        print(\"Solution {0} of {1}\".format(iso, len(group)))\n",
    "        print(so.score, \"-\", so.ndmScore, \"-\", so.aggrScore)\n",
    "        #print(\"Islands: \", pydata.islNum(so))\n",
    "        #if not pydata.isCont(so):\n",
    "        #    print(\"NOT CONTINUOUS!!!\")\n",
    "        #print(so.toBitList())\n",
    "        print(myfile.tile2str(so))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
